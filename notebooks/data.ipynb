{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d9ca63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Fetching reviews for Commercial Bank of Ethiopia...\n",
      "üì¶ Fetching reviews for Bank of Abyssinia...\n",
      "üì¶ Fetching reviews for Dashen Bank...\n",
      "\n",
      "‚úÖ Scraping complete. Data saved to: bank_reviews.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amenzz\\AppData\\Local\\Temp\\ipykernel_17540\\3531052261.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_reviews = pd.concat([all_reviews, df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from google_play_scraper import Sort, reviews\n",
    "import pandas as pd\n",
    "\n",
    "# List of bank apps with package names (update if incorrect)\n",
    "apps = {\n",
    "    \"Commercial Bank of Ethiopia\": \"com.combanketh.mobilebanking\",\n",
    "    \"Bank of Abyssinia\": \"com.boa.boaMobileBanking\",\n",
    "    \"Dashen Bank\": \"com.cr2.amolelight\"\n",
    "}\n",
    "\n",
    "\n",
    "# Desired number of reviews per app\n",
    "N_REVIEWS = 400\n",
    "\n",
    "# Master DataFrame to hold all reviews\n",
    "all_reviews = pd.DataFrame()\n",
    "\n",
    "for bank_name, app_id in apps.items():\n",
    "    print(f\"üì¶ Fetching reviews for {bank_name}...\")\n",
    "    \n",
    "    reviews_list, _ = reviews(\n",
    "        app_id,\n",
    "        lang='en',\n",
    "        country='us',\n",
    "        sort=Sort.NEWEST,\n",
    "        count=N_REVIEWS,\n",
    "        filter_score_with=None  # Pull all ratings, not just 1-star, etc.\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(reviews_list)\n",
    "    df['bank'] = bank_name\n",
    "    all_reviews = pd.concat([all_reviews, df], ignore_index=True)\n",
    "\n",
    "# Save the scraped data\n",
    "output_path = \"bank_reviews.csv\"\n",
    "all_reviews.to_csv(output_path, index=False)\n",
    "print(f\"\\n‚úÖ Scraping complete. Data saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ad19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Clean file saved to: bank_reviews_clean.csv\n",
      "                                              review  rating        date  \\\n",
      "0                         So bad now and hard to use       5  2025-06-09   \n",
      "1  it is so amazing app. but, it is better to upd...       5  2025-06-09   \n",
      "2                                         v.good app       4  2025-06-09   \n",
      "3                                      very good app       1  2025-06-09   \n",
      "4           Very amazing app indeed. I'm enjoying it       5  2025-06-08   \n",
      "\n",
      "                          bank       source  \n",
      "0  Commercial Bank of Ethiopia  Google Play  \n",
      "1  Commercial Bank of Ethiopia  Google Play  \n",
      "2  Commercial Bank of Ethiopia  Google Play  \n",
      "3  Commercial Bank of Ethiopia  Google Play  \n",
      "4  Commercial Bank of Ethiopia  Google Play  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1Ô∏è‚É£  Load the raw scrape\n",
    "raw_path = Path(\"bank_reviews.csv\")\n",
    "df = pd.read_csv(raw_path)\n",
    "\n",
    "# 2Ô∏è‚É£  Basic cleaning\n",
    "# -------------------------------------------------\n",
    "# a) Drop exact duplicates based on the reviewId (if present)\n",
    "if \"reviewId\" in df.columns:\n",
    "    df = df.drop_duplicates(subset=\"reviewId\")\n",
    "\n",
    "# b) Drop rows with missing review text or rating\n",
    "df = df.dropna(subset=[\"content\", \"score\"])\n",
    "\n",
    "# 3Ô∏è‚É£  Normalise the date\n",
    "# -------------------------------------------------\n",
    "# 'at' column from google-play-scraper is a full timestamp\n",
    "df[\"date\"] = pd.to_datetime(df[\"at\"], errors=\"coerce\").dt.date  # keep only YYYY-MM-DD\n",
    "df = df.dropna(subset=[\"date\"])  # remove rows we couldn‚Äôt parse\n",
    "\n",
    "# 4Ô∏è‚É£  Keep / rename the requested columns\n",
    "# -------------------------------------------------\n",
    "df_clean = df.rename(columns={\n",
    "    \"content\": \"review\",\n",
    "    \"score\": \"rating\"\n",
    "})[[\"review\", \"rating\", \"date\", \"bank\"]]\n",
    "\n",
    "df_clean[\"source\"] = \"Google Play\"\n",
    "\n",
    "# 5Ô∏è‚É£  Save the cleaned file\n",
    "# -------------------------------------------------\n",
    "clean_path = Path(\"bank_reviews_clean.csv\")\n",
    "df_clean.to_csv(clean_path, index=False)\n",
    "\n",
    "print(\"‚úÖ Clean file saved to:\", clean_path)\n",
    "print(df_clean.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0bf73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè¶ Banks found in dataset: ['Commercial Bank of Ethiopia' 'Bank of Abyssinia' 'Dashen Bank']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"bank_reviews_clean.csv\")\n",
    "\n",
    "# Show unique bank names\n",
    "print(\"üè¶ Banks found in dataset:\", df['bank'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf20e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Number of Reviews Per Bank:\n",
      "bank\n",
      "Commercial Bank of Ethiopia    400\n",
      "Bank of Abyssinia              400\n",
      "Dashen Bank                    400\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üß™ Percentage of Missing Data Per Column:\n",
      "reviewId                 0.00\n",
      "userName                 0.00\n",
      "userImage                0.00\n",
      "content                  0.00\n",
      "score                    0.00\n",
      "thumbsUpCount            0.00\n",
      "reviewCreatedVersion    25.33\n",
      "at                       0.00\n",
      "replyContent            99.92\n",
      "repliedAt               99.92\n",
      "appVersion              25.33\n",
      "bank                     0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned dataset\n",
    "df = pd.read_csv(\"bank_reviews.csv\")  # Replace with your actual CSV file path\n",
    "\n",
    "# 1. üî¢ Number of reviews per bank\n",
    "print(\"üîç Number of Reviews Per Bank:\")\n",
    "print(df['bank'].value_counts())\n",
    "\n",
    "# 2. üìâ Percentage of missing data per column\n",
    "print(\"\\nüß™ Percentage of Missing Data Per Column:\")\n",
    "missing_percent = df.isnull().mean() * 100\n",
    "print(missing_percent.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73963cd",
   "metadata": {},
   "source": [
    "# Task 2 Sentiment and Thematic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae6a172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment_label  \\\n",
      "0                         So bad now and hard to use        NEGATIVE   \n",
      "1  it is so amazing app. but, it is better to upd...        POSITIVE   \n",
      "2                                         v.good app        POSITIVE   \n",
      "3                                      very good app        POSITIVE   \n",
      "4           Very amazing app indeed. I'm enjoying it        POSITIVE   \n",
      "\n",
      "   sentiment_score  \n",
      "0         0.999806  \n",
      "1         0.949643  \n",
      "2         0.995270  \n",
      "3         0.999868  \n",
      "4         0.999882  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the cleaned reviews\n",
    "df = pd.read_csv(\"bank_reviews_clean.csv\")\n",
    "\n",
    "# Load the sentiment-analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Function to apply sentiment analysis\n",
    "def analyze_sentiment(text):\n",
    "    result = sentiment_analyzer(text[:512])[0]  # truncate long reviews\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    return label, score\n",
    "\n",
    "# Apply to each review\n",
    "df[['sentiment_label', 'sentiment_score']] = df['review'].apply(lambda x: pd.Series(analyze_sentiment(x)))\n",
    "\n",
    "# View sample results\n",
    "print(df[['review', 'sentiment_label', 'sentiment_score']].head())\n",
    "\n",
    "# Optionally, save to new CSV\n",
    "df.to_csv(\"bank_reviews_with_sentiment.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "278eba1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review vader_label  vader_score\n",
      "0                         So bad now and hard to use    NEGATIVE      -0.6361\n",
      "1  it is so amazing app. but, it is better to upd...    POSITIVE       0.9049\n",
      "2                                         v.good app     NEUTRAL       0.0000\n",
      "3                                      very good app    POSITIVE       0.4927\n",
      "4           Very amazing app indeed. I'm enjoying it    POSITIVE       0.8173\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load the cleaned reviews\n",
    "df = pd.read_csv(\"bank_reviews_clean.csv\")\n",
    "\n",
    "# Initialize VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define VADER sentiment scoring\n",
    "def vader_sentiment(text):\n",
    "    vs = analyzer.polarity_scores(text)\n",
    "    compound = vs['compound']\n",
    "    if compound >= 0.05:\n",
    "        label = 'POSITIVE'\n",
    "    elif compound <= -0.05:\n",
    "        label = 'NEGATIVE'\n",
    "    else:\n",
    "        label = 'NEUTRAL'\n",
    "    return label, compound\n",
    "\n",
    "# Apply VADER sentiment analysis\n",
    "df[['vader_label', 'vader_score']] = df['review'].apply(lambda x: pd.Series(vader_sentiment(x)))\n",
    "\n",
    "# Display a few results\n",
    "print(df[['review', 'vader_label', 'vader_score']].head())\n",
    "\n",
    "# Optional: Save with VADER sentiment\n",
    "df.to_csv(\"bank_reviews_with_vader.csv\", index=False)\n",
    "#compare DistilBERT and VADER outputs side-by-side\n",
    "# print(df[['review', 'sentiment_label', 'sentiment_score', 'vader_label', 'vader_score']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0057266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Aggregated Sentiment by Bank and Rating:\n",
      "\n",
      "                           bank  rating  mean_vader_score  review_count\n",
      "0             Bank of Abyssinia       1         -0.157021           164\n",
      "1             Bank of Abyssinia       2          0.132891            11\n",
      "2             Bank of Abyssinia       3          0.192516            31\n",
      "3             Bank of Abyssinia       4          0.333017            18\n",
      "4             Bank of Abyssinia       5          0.348110           176\n",
      "5   Commercial Bank of Ethiopia       1          0.003700            49\n",
      "6   Commercial Bank of Ethiopia       2          0.053775            16\n",
      "7   Commercial Bank of Ethiopia       3          0.174140            20\n",
      "8   Commercial Bank of Ethiopia       4          0.333955            40\n",
      "9   Commercial Bank of Ethiopia       5          0.422128           275\n",
      "10                  Dashen Bank       1         -0.084621            61\n",
      "11                  Dashen Bank       2          0.023394            16\n",
      "12                  Dashen Bank       3          0.102384            31\n",
      "13                  Dashen Bank       4          0.343643            35\n",
      "14                  Dashen Bank       5          0.404699           257\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# 1. Load cleaned reviews\n",
    "df = pd.read_csv(\"bank_reviews_clean.csv\")\n",
    "\n",
    "# 2. Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# 3. Define sentiment function\n",
    "def vader_sentiment(text):\n",
    "    vs = analyzer.polarity_scores(text)\n",
    "    compound = vs['compound']\n",
    "    if compound >= 0.05:\n",
    "        label = 'POSITIVE'\n",
    "    elif compound <= -0.05:\n",
    "        label = 'NEGATIVE'\n",
    "    else:\n",
    "        label = 'NEUTRAL'\n",
    "    return label, compound\n",
    "\n",
    "# 4. Apply sentiment analysis to each review\n",
    "df[['vader_label', 'vader_score']] = df['review'].apply(lambda x: pd.Series(vader_sentiment(x)))\n",
    "\n",
    "# 5. Save to file with sentiment results (optional)\n",
    "df.to_csv(\"bank_reviews_with_vader.csv\", index=False)\n",
    "\n",
    "# 6. Aggregate by bank and rating\n",
    "agg_sentiment = df.groupby(['bank', 'rating']).agg(\n",
    "    mean_vader_score=('vader_score', 'mean'),\n",
    "    review_count=('review', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# 7. Show results\n",
    "print(\"\\n‚úÖ Aggregated Sentiment by Bank and Rating:\\n\")\n",
    "print(agg_sentiment)\n",
    "\n",
    "# 8. Save aggregation to CSV (optional)\n",
    "agg_sentiment.to_csv(\"bank_reviews_aggregated_sentiment.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7398f6e7",
   "metadata": {},
   "source": [
    "# Thematic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff5a80c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Top TF-IDF Keywords:\n",
      "app                  60.57\n",
      "good                 24.10\n",
      "bank                 22.74\n",
      "work                 19.06\n",
      "use                  18.86\n",
      "banking              16.23\n",
      "application          15.90\n",
      "best                 15.23\n",
      "mobile               13.82\n",
      "like                 13.47\n",
      "working              11.99\n",
      "time                 11.70\n",
      "mobile banking       11.61\n",
      "update               10.88\n",
      "make                 10.81\n",
      "·äê·ãç                   10.51\n",
      "fix                  10.45\n",
      "doesn                10.33\n",
      "don                  10.22\n",
      "worst                10.05\n",
      "cbe                  10.03\n",
      "easy                 9.61\n",
      "nice                 9.22\n",
      "account              8.82\n",
      "screenshot           8.80\n",
      "better               8.54\n",
      "money                8.42\n",
      "good app             8.39\n",
      "need                 8.23\n",
      "slow                 8.12\n",
      "\n",
      "‚úÖ Grouped Keywords by Theme:\n",
      "login_issues: set()\n",
      "performance: {'slow'}\n",
      "customer_service: set()\n",
      "transactions: set()\n",
      "usability: set()\n",
      "\n",
      "‚úÖ Top Noun Phrases from spaCy:\n",
      "it                             372\n",
      "i                              267\n",
      "you                            82\n",
      "this app                       79\n",
      "the app                        57\n",
      "this                           38\n",
      "me                             35\n",
      "that                           27\n",
      "we                             17\n",
      "they                           17\n",
      "what                           15\n",
      "money                          15\n",
      "which                          11\n",
      "boa                            11\n",
      "the bank                       10\n",
      "cbe                            10\n",
      "this bank                      10\n",
      "us                             8\n",
      "ethiopia                       8\n",
      "mobile banking                 8\n",
      "app                            8\n",
      "dashen bank                    8\n",
      "them                           7\n",
      "good app                       7\n",
      "my money                       7\n",
      "my account                     7\n",
      "the application                7\n",
      "developer options              7\n",
      "amole                          7\n",
      "time                           6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Load cleaned reviews\n",
    "df = pd.read_csv(\"bank_reviews_clean.csv\")\n",
    "\n",
    "# Filter short reviews\n",
    "df = df[df['review'].str.len() > 20]\n",
    "\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ TF-IDF Keyword Extraction\n",
    "# -------------------------------\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),     # unigrams and bigrams\n",
    "    max_df=0.9,\n",
    "    min_df=5                # appears in at least 5 reviews\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(df['review'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "def get_top_keywords(matrix, features, top_n=30):\n",
    "    sums = matrix.sum(axis=0).A1\n",
    "    data = [(word, sums[idx]) for idx, word in enumerate(features)]\n",
    "    return sorted(data, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "top_keywords = get_top_keywords(tfidf_matrix, feature_names, top_n=30)\n",
    "\n",
    "print(\"\\n‚úÖ Top TF-IDF Keywords:\")\n",
    "for word, score in top_keywords:\n",
    "    print(f\"{word:<20} {score:.2f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Manual Rule-Based Clustering\n",
    "# -------------------------------\n",
    "theme_map = {\n",
    "    \"login_issues\": [\"login\", \"sign in\", \"authentication\", \"credentials\"],\n",
    "    \"performance\": [\"slow\", \"crash\", \"freeze\", \"lag\", \"unresponsive\"],\n",
    "    \"customer_service\": [\"support\", \"help\", \"customer care\", \"agent\", \"response\"],\n",
    "    \"transactions\": [\"transfer\", \"deposit\", \"withdraw\", \"balance\", \"payment\"],\n",
    "    \"usability\": [\"interface\", \"design\", \"navigation\", \"user-friendly\", \"easy to use\"]\n",
    "}\n",
    "\n",
    "# Create reverse mapping\n",
    "keyword_to_theme = {}\n",
    "for theme, words in theme_map.items():\n",
    "    for w in words:\n",
    "        keyword_to_theme[w.lower()] = theme\n",
    "\n",
    "# Group keywords into themes\n",
    "theme_keywords = {theme: [] for theme in theme_map}\n",
    "for word, score in top_keywords:\n",
    "    for key in keyword_to_theme:\n",
    "        if key in word:\n",
    "            theme_keywords[keyword_to_theme[key]].append(word)\n",
    "\n",
    "# Show clustered keywords\n",
    "print(\"\\n‚úÖ Grouped Keywords by Theme:\")\n",
    "for theme, keywords in theme_keywords.items():\n",
    "    print(f\"{theme}: {set(keywords)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ (Optional) spaCy Phrase Extraction\n",
    "# -------------------------------\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_noun_phrases(text):\n",
    "    doc = nlp(text)\n",
    "    return [chunk.text.lower() for chunk in doc.noun_chunks if len(chunk.text.split()) <= 3]\n",
    "\n",
    "# Apply to all reviews\n",
    "all_phrases = df['review'].apply(extract_noun_phrases)\n",
    "flat_phrases = [phrase for sublist in all_phrases for phrase in sublist]\n",
    "phrase_counts = Counter(flat_phrases).most_common(30)\n",
    "\n",
    "print(\"\\n‚úÖ Top Noun Phrases from spaCy:\")\n",
    "for phrase, count in phrase_counts:\n",
    "    print(f\"{phrase:<30} {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c432f68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Themes for Commercial Bank of Ethiopia:\n",
      " - Other: 41 keywords\n",
      " - User Interface & Experience: 5 keywords\n",
      " - Transaction Performance: 2 keywords\n",
      " - Feature Requests: 1 keywords\n",
      " - Account Access Issues: 1 keywords\n",
      "\n",
      "üìä Themes for Bank of Abyssinia:\n",
      " - Other: 41 keywords\n",
      " - User Interface & Experience: 6 keywords\n",
      " - Feature Requests: 2 keywords\n",
      " - Transaction Performance: 1 keywords\n",
      "\n",
      "üìä Themes for Dashen Bank:\n",
      " - Other: 38 keywords\n",
      " - User Interface & Experience: 4 keywords\n",
      " - Feature Requests: 3 keywords\n",
      " - Account Access Issues: 2 keywords\n",
      " - Transaction Performance: 2 keywords\n",
      " - Customer Support: 1 keywords\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"bank_reviews_clean.csv\")\n",
    "df = df[df['review'].str.len() > 20]  # filter out very short reviews\n",
    "\n",
    "# Load spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: Extract TF-IDF Keywords\n",
    "# -------------------------------\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_df=0.9, min_df=3)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['review'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Get top N keywords\n",
    "def get_top_keywords(tfidf_matrix, feature_names, top_n=50):\n",
    "    sums = tfidf_matrix.sum(axis=0).A1\n",
    "    keywords = [(feature_names[i], sums[i]) for i in range(len(sums))]\n",
    "    return sorted(keywords, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 2: Extract Noun Phrases\n",
    "# -------------------------------\n",
    "def extract_noun_phrases(text):\n",
    "    doc = nlp(text)\n",
    "    return [chunk.text.lower().strip() for chunk in doc.noun_chunks if len(chunk.text.split()) <= 3]\n",
    "\n",
    "df[\"noun_phrases\"] = df[\"review\"].apply(extract_noun_phrases)\n",
    "\n",
    "# Flatten and count phrases\n",
    "flat_phrases = [phrase for phrases in df[\"noun_phrases\"] for phrase in phrases]\n",
    "top_phrases = Counter(flat_phrases).most_common(50)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 3: Define Theme Mapping Logic\n",
    "# -------------------------------\n",
    "theme_definitions = {\n",
    "    \"Account Access Issues\": [\"login\", \"sign in\", \"authentication\", \"password\", \"otp\", \"access\"],\n",
    "    \"Transaction Performance\": [\"transfer\", \"deposit\", \"payment\", \"balance\", \"slow\", \"delay\", \"failed\", \"transaction\"],\n",
    "    \"User Interface & Experience\": [\"interface\", \"design\", \"navigation\", \"user-friendly\", \"app\", \"crash\", \"freeze\", \"slow\", \"responsive\"],\n",
    "    \"Customer Support\": [\"support\", \"help\", \"agent\", \"service\", \"response\", \"call\", \"email\"],\n",
    "    \"Feature Requests\": [\"feature\", \"add\", \"option\", \"would like\", \"missing\", \"need\", \"request\"]\n",
    "}\n",
    "\n",
    "def match_theme(keyword):\n",
    "    keyword_lower = keyword.lower()\n",
    "    for theme, terms in theme_definitions.items():\n",
    "        if any(term in keyword_lower for term in terms):\n",
    "            return theme\n",
    "    return \"Other\"\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 4: Group by Bank\n",
    "# -------------------------------\n",
    "bank_theme_keywords = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for bank in df[\"bank\"].unique():\n",
    "    bank_df = df[df[\"bank\"] == bank]\n",
    "\n",
    "    # Extract TF-IDF per bank\n",
    "    bank_vector = vectorizer.fit_transform(bank_df[\"review\"])\n",
    "    bank_keywords = get_top_keywords(bank_vector, vectorizer.get_feature_names_out(), top_n=50)\n",
    "\n",
    "    for keyword, score in bank_keywords:\n",
    "        theme = match_theme(keyword)\n",
    "        bank_theme_keywords[bank][theme] += 1\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 5: Display Final Themes Per Bank\n",
    "# -------------------------------\n",
    "for bank, themes in bank_theme_keywords.items():\n",
    "    print(f\"\\nüìä Themes for {bank}:\")\n",
    "    sorted_themes = sorted(themes.items(), key=lambda x: x[1], reverse=True)\n",
    "    for theme, count in sorted_themes:\n",
    "        print(f\" - {theme}: {count} keywords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fdc9b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline completed, results saved to processed_bank_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "from textblob import TextBlob  # For simple sentiment analysis\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"bank_reviews_clean.csv\")\n",
    "df = df[df['review'].str.len() > 20].copy()  # Filter very short reviews\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# --- Preprocessing function ---\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [\n",
    "        token.lemma_ for token in doc\n",
    "        if not token.is_stop and not token.is_punct and token.is_alpha\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"cleaned_review\"] = df[\"review\"].apply(preprocess_text)\n",
    "\n",
    "# --- Sentiment Analysis function using TextBlob ---\n",
    "def analyze_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    # Simple labeling logic\n",
    "    if polarity > 0.1:\n",
    "        label = \"Positive\"\n",
    "    elif polarity < -0.1:\n",
    "        label = \"Negative\"\n",
    "    else:\n",
    "        label = \"Neutral\"\n",
    "    return label, polarity\n",
    "\n",
    "df[[\"sentiment_label\", \"sentiment_score\"]] = df[\"cleaned_review\"].apply(\n",
    "    lambda x: pd.Series(analyze_sentiment(x))\n",
    ")\n",
    "\n",
    "# --- Theme definitions ---\n",
    "theme_definitions = {\n",
    "    \"Account Access Issues\": [\"login\", \"sign in\", \"authentication\", \"password\", \"otp\", \"access\"],\n",
    "    \"Transaction Performance\": [\"transfer\", \"deposit\", \"payment\", \"balance\", \"slow\", \"delay\", \"failed\", \"transaction\"],\n",
    "    \"User Interface & Experience\": [\"interface\", \"design\", \"navigation\", \"user-friendly\", \"app\", \"crash\", \"freeze\", \"slow\", \"responsive\"],\n",
    "    \"Customer Support\": [\"support\", \"help\", \"agent\", \"service\", \"response\", \"call\", \"email\"],\n",
    "    \"Feature Requests\": [\"feature\", \"add\", \"option\", \"would like\", \"missing\", \"need\", \"request\"]\n",
    "}\n",
    "\n",
    "# --- Theme matching function ---\n",
    "def match_themes(text):\n",
    "    matched = set()\n",
    "    text_lower = text.lower()\n",
    "    for theme, terms in theme_definitions.items():\n",
    "        if any(term in text_lower for term in terms):\n",
    "            matched.add(theme)\n",
    "    if not matched:\n",
    "        matched.add(\"Other\")\n",
    "    return list(matched)\n",
    "\n",
    "df[\"identified_themes\"] = df[\"cleaned_review\"].apply(match_themes)\n",
    "\n",
    "# --- Save to CSV ---\n",
    "df = df.reset_index(drop=True)  # ensure clean numeric index\n",
    "df['review_id'] = df.index + 1  # start IDs at 1 (optional)\n",
    "\n",
    "output_columns = [\"review_id\", \"review\", \"sentiment_label\", \"sentiment_score\", \"identified_themes\"]\n",
    "\n",
    "df.to_csv(\"processed_bank_reviews.csv\", columns=output_columns, index=False)\n",
    "\n",
    "\n",
    "print(\"Pipeline completed, results saved to processed_bank_reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a63ed28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"bank_reviews_clean.csv\")\n",
    "df = df[df['review'].str.len() > 20]\n",
    "\n",
    "# Function to extract noun phrases using spaCy (max 3 words)\n",
    "def extract_noun_phrases(text):\n",
    "    doc = nlp(text.lower())\n",
    "    return [chunk.text.strip() for chunk in doc.noun_chunks if len(chunk.text.split()) <= 3]\n",
    "\n",
    "# Prepare storage for results\n",
    "bank_keywords = {}\n",
    "\n",
    "for bank in df['bank'].unique():\n",
    "    bank_df = df[df['bank'] == bank]\n",
    "    \n",
    "    # --- TF-IDF keywords ---\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=0.85, min_df=3)\n",
    "    tfidf_matrix = vectorizer.fit_transform(bank_df['review'])\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    sums = tfidf_matrix.sum(axis=0).A1\n",
    "    keywords_scores = list(zip(feature_names, sums))\n",
    "    keywords_scores = sorted(keywords_scores, key=lambda x: x[1], reverse=True)[:100]  # top 100\n",
    "    \n",
    "    # --- spaCy noun phrases ---\n",
    "    noun_phrases = []\n",
    "    for text in bank_df['review']:\n",
    "        noun_phrases.extend(extract_noun_phrases(text))\n",
    "    \n",
    "    # Count noun phrases and take top 50\n",
    "    np_counts = Counter(noun_phrases).most_common(50)\n",
    "    \n",
    "    # Combine keywords (TF-IDF + noun phrases) with scores/counts\n",
    "    combined_keywords = {}\n",
    "    for k, score in keywords_scores:\n",
    "        combined_keywords[k] = combined_keywords.get(k, 0) + score\n",
    "    for np, count in np_counts:\n",
    "        combined_keywords[np] = combined_keywords.get(np, 0) + count * 0.5  # weigh noun phrases lower\n",
    "    \n",
    "    # Get combined top keywords for clustering\n",
    "    top_keywords = sorted(combined_keywords.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "    bank_keywords[bank] = [kw for kw, score in top_keywords]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b09bb8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_phrase_vector(phrase):\n",
    "    # average word vectors for multi-word phrases\n",
    "    doc = nlp(phrase)\n",
    "    if len(doc) == 0:\n",
    "        return np.zeros(nlp.vocab.vectors_length)\n",
    "    return doc.vector\n",
    "\n",
    "# For each bank, cluster keywords into 3‚Äì5 themes\n",
    "bank_clusters = {}\n",
    "\n",
    "for bank, keywords in bank_keywords.items():\n",
    "    vectors = np.array([get_phrase_vector(k) for k in keywords])\n",
    "    \n",
    "    # Choose number of clusters dynamically or fixed (e.g., 4)\n",
    "    n_clusters = 4 if len(keywords) >= 4 else len(keywords)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(vectors)\n",
    "    \n",
    "    clusters = defaultdict(list)\n",
    "    for label, keyword in zip(labels, keywords):\n",
    "        clusters[label].append(keyword)\n",
    "    \n",
    "    bank_clusters[bank] = clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e375d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Themes for Commercial Bank of Ethiopia:\n",
      " Theme 1:\n",
      "    it, i, you, screenshot, bank, application, banking, use, update, me\n",
      " Theme 3:\n",
      "    app, cbe, this app, the app, mobile banking, good app, mobile, time, fix, ·äê·ãç\n",
      " Theme 4:\n",
      "    good, like, best, nice, great, that, easy, amazing, reliable, really\n",
      " Theme 2:\n",
      "    make, work, using, account, need, thank, send, try, working, feature\n",
      "\n",
      "Themes for Bank of Abyssinia:\n",
      " Theme 4:\n",
      "    it, i, you, me, they, transactions, apps, works, crashes, times\n",
      " Theme 2:\n",
      "    app, bank, boa, money, work, mobile banking, banking, use, working, doesn\n",
      " Theme 3:\n",
      "    this app, the app, this, that, what, like, the bank, my phone, this bank, dont\n",
      " Theme 1:\n",
      "    worst, better, best, just, frequently, long\n",
      "\n",
      "Themes for Dashen Bank:\n",
      " Theme 3:\n",
      "    it, i, app, you, this app, bank, amole, the app, dashen bank, good app\n",
      " Theme 1:\n",
      "    good, best, dashen, fast, nice, easy, slow, mobile, that, simple\n",
      " Theme 2:\n",
      "    use, update, work, account, like, used, transfer, working, make, need\n",
      " Theme 4:\n",
      "    what, which\n"
     ]
    }
   ],
   "source": [
    "for bank, clusters in bank_clusters.items():\n",
    "    print(f\"\\nThemes for {bank}:\")\n",
    "    for cluster_id, keywords in clusters.items():\n",
    "        print(f\" Theme {cluster_id + 1}:\")\n",
    "        print(\"   \", \", \".join(keywords[:10]))  # show top 10 keywords in cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "580cccfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Themes for Commercial Bank of Ethiopia:\n",
      " Theme 1: it, i, you, screenshot, bank, application, banking, use, update, me\n",
      " Theme 3: app, cbe, this app, the app, mobile banking, good app, mobile, time, fix, ·äê·ãç\n",
      " Theme 4: good, like, best, nice, great, that, easy, amazing, reliable, really\n",
      " Theme 2: make, work, using, account, need, thank, send, try, working, feature\n",
      "\n",
      "üéØ Themes for Bank of Abyssinia:\n",
      " Theme 4: it, i, you, me, they, transactions, apps, works, crashes, times\n",
      " Theme 2: app, bank, boa, money, work, mobile banking, banking, use, working, doesn\n",
      " Theme 3: this app, the app, this, that, what, like, the bank, my phone, this bank, dont\n",
      " Theme 1: worst, better, best, just, frequently, long\n",
      "\n",
      "üéØ Themes for Dashen Bank:\n",
      " Theme 3: it, i, app, you, this app, bank, amole, the app, dashen bank, good app\n",
      " Theme 1: good, best, dashen, fast, nice, easy, slow, mobile, that, simple\n",
      " Theme 2: use, update, work, account, like, used, transfer, working, make, need\n",
      " Theme 4: what, which\n",
      "\n",
      "‚úÖ Pipeline completed and saved to processed_bank_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load spaCy model once\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def load_and_filter_data(filepath, min_review_len=20):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df[df['review'].str.len() > min_review_len].copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def extract_noun_phrases(text):\n",
    "    doc = nlp(text.lower())\n",
    "    return [chunk.text.strip() for chunk in doc.noun_chunks if len(chunk.text.split()) <= 3]\n",
    "\n",
    "def compute_sentiment(text):\n",
    "    # TextBlob polarity: -1 (negative) to +1 (positive)\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def get_tfidf_keywords(corpus, top_n=100):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=0.85, min_df=3)\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    sums = tfidf_matrix.sum(axis=0).A1\n",
    "    keywords_scores = list(zip(feature_names, sums))\n",
    "    return sorted(keywords_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "def combine_keywords(tfidf_keywords, noun_phrases_counts, weight_np=0.5, top_n=100):\n",
    "    combined = defaultdict(float)\n",
    "    for kw, score in tfidf_keywords:\n",
    "        combined[kw] += score\n",
    "    for np, count in noun_phrases_counts:\n",
    "        combined[np] += count * weight_np\n",
    "    combined_sorted = sorted(combined.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    return [kw for kw, _ in combined_sorted]\n",
    "\n",
    "def phrase_vector(phrase):\n",
    "    doc = nlp(phrase)\n",
    "    if len(doc) == 0:\n",
    "        return np.zeros(nlp.vocab.vectors_length)\n",
    "    return doc.vector\n",
    "\n",
    "def cluster_keywords(keywords, n_clusters=4):\n",
    "    vectors = np.array([phrase_vector(k) for k in keywords])\n",
    "    n_clusters = min(n_clusters, len(keywords))\n",
    "    if n_clusters == 0:\n",
    "        return {}\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(vectors)\n",
    "    clusters = defaultdict(list)\n",
    "    for label, keyword in zip(labels, keywords):\n",
    "        clusters[label].append(keyword)\n",
    "    return clusters\n",
    "\n",
    "def assign_themes_to_reviews(df, theme_keywords_per_bank):\n",
    "    # For each review, assign themes that appear in its text\n",
    "    themes_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        review_text = row['review'].lower()\n",
    "        bank = row['bank']\n",
    "        themes = []\n",
    "        for theme_id, keywords in theme_keywords_per_bank.get(bank, {}).items():\n",
    "            if any(k in review_text for k in keywords):\n",
    "                themes.append(f\"Theme {theme_id+1}\")\n",
    "        themes_list.append(\", \".join(themes) if themes else \"Other\")\n",
    "    df['identified_themes'] = themes_list\n",
    "    return df\n",
    "\n",
    "def pipeline(filepath, n_themes=4):\n",
    "    df = load_and_filter_data(filepath)\n",
    "    \n",
    "    # Sentiment scoring\n",
    "    df['sentiment_score'] = df['review'].apply(compute_sentiment)\n",
    "    df['sentiment_label'] = df['sentiment_score'].apply(lambda x: 'positive' if x > 0.1 else ('negative' if x < -0.1 else 'neutral'))\n",
    "    \n",
    "    bank_theme_keywords = {}\n",
    "    \n",
    "    for bank in df['bank'].unique():\n",
    "        bank_df = df[df['bank'] == bank]\n",
    "        \n",
    "        # Extract TF-IDF keywords\n",
    "        tfidf_keywords = get_tfidf_keywords(bank_df['review'], top_n=100)\n",
    "        \n",
    "        # Extract noun phrases counts\n",
    "        all_noun_phrases = []\n",
    "        for text in bank_df['review']:\n",
    "            all_noun_phrases.extend(extract_noun_phrases(text))\n",
    "        np_counts = Counter(all_noun_phrases).most_common(50)\n",
    "        \n",
    "        # Combine keywords\n",
    "        combined_keywords = combine_keywords(tfidf_keywords, np_counts, weight_np=0.5, top_n=100)\n",
    "        \n",
    "        # Cluster combined keywords into themes\n",
    "        clusters = cluster_keywords(combined_keywords, n_clusters=n_themes)\n",
    "        bank_theme_keywords[bank] = clusters\n",
    "        \n",
    "    # Assign themes per review\n",
    "    df = assign_themes_to_reviews(df, bank_theme_keywords)\n",
    "    \n",
    "    # Show themes summary per bank\n",
    "    for bank, clusters in bank_theme_keywords.items():\n",
    "        print(f\"\\nüéØ Themes for {bank}:\")\n",
    "        for cid, keywords in clusters.items():\n",
    "            print(f\" Theme {cid+1}: {', '.join(keywords[:10])}\")\n",
    "    \n",
    "    # Save results to CSV\n",
    "    output_cols = ['review', 'bank', 'sentiment_label', 'sentiment_score', 'identified_themes']\n",
    "    df.to_csv(\"processed_bank_reviews.csv\", columns=output_cols, index=False)\n",
    "    print(\"\\n‚úÖ Pipeline completed and saved to processed_bank_reviews.csv\")\n",
    "    \n",
    "    return df, bank_theme_keywords\n",
    "\n",
    "# Run pipeline\n",
    "df_result, themes_per_bank = pipeline(\"bank_reviews_clean.csv\", n_themes=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba18905",
   "metadata": {},
   "source": [
    "# Task 3 Store Cleaned Data in Oracle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57193b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Oracle connection info\n",
    "username = \"***********\"\n",
    "password = \"*********\"\n",
    "dsn = \"localhost/XEPDB1\"  # Adjust for your Oracle XE service name and host\n",
    "\n",
    "connection = cx_Oracle.connect(username, password, dsn)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Step 1: Insert unique banks into banks table\n",
    "banks = df_result['bank'].unique()\n",
    "bank_id_map = {}\n",
    "\n",
    "for bank_name in banks:\n",
    "    cursor.execute(\"INSERT INTO banks (bank_name) VALUES (:1) RETURNING bank_id INTO :2\",\n",
    "                   (bank_name, cx_Oracle.NUMBER))\n",
    "    bank_id = cursor.getimplicitresults()[0][0]\n",
    "    # If RETURNING doesn't work, fallback:\n",
    "    # cursor.execute(\"SELECT bank_id FROM banks WHERE bank_name=:1\", (bank_name,))\n",
    "    # bank_id = cursor.fetchone()[0]\n",
    "    bank_id_map[bank_name] = bank_id\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "# Alternative approach to get IDs (if RETURNING is problematic):\n",
    "# Insert bank names, then query all to build bank_id_map.\n",
    "\n",
    "cursor.execute(\"SELECT bank_id, bank_name FROM banks\")\n",
    "for bank_id, bank_name in cursor.fetchall():\n",
    "    bank_id_map[bank_name] = bank_id\n",
    "\n",
    "# Step 2: Insert reviews\n",
    "insert_sql = \"\"\"\n",
    "    INSERT INTO reviews (bank_id, review_text, sentiment_label, sentiment_score, identified_themes)\n",
    "    VALUES (:bank_id, :review_text, :sentiment_label, :sentiment_score, :identified_themes)\n",
    "\"\"\"\n",
    "\n",
    "data_to_insert = []\n",
    "for idx, row in df_result.iterrows():\n",
    "    data_to_insert.append((\n",
    "        bank_id_map[row['bank']],\n",
    "        row['review'],\n",
    "        row['sentiment_label'],\n",
    "        float(row['sentiment_score']),\n",
    "        row['identified_themes']\n",
    "    ))\n",
    "\n",
    "cursor.executemany(insert_sql, data_to_insert)\n",
    "connection.commit()\n",
    "\n",
    "print(f\"Inserted {len(data_to_insert)} reviews into Oracle DB\")\n",
    "\n",
    "cursor.close()\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcca407",
   "metadata": {},
   "source": [
    "#Task four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top positive and negative themes\n",
    "positive_reviews = df[df[\"sentiment_label\"] == \"positive\"]\n",
    "negative_reviews = df[df[\"sentiment_label\"] == \"negative\"]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Flatten themes for positive and negative\n",
    "positive_themes = [theme for themes in positive_reviews[\"identified_themes\"] for theme in themes.split(\", \")]\n",
    "negative_themes = [theme for themes in negative_reviews[\"identified_themes\"] for theme in themes.split(\", \")]\n",
    "\n",
    "# Count them\n",
    "top_positive = Counter(positive_themes).most_common(5)\n",
    "top_negative = Counter(negative_themes).most_common(5)\n",
    "\n",
    "print(\"‚úÖ Top Drivers:\")\n",
    "for theme, count in top_positive:\n",
    "    print(f\"- {theme} ({count} mentions)\")\n",
    "\n",
    "print(\"\\n‚ùå Top Pain Points:\")\n",
    "for theme, count in top_negative:\n",
    "    print(f\"- {theme} ({count} mentions)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200eae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Average sentiment by bank\n",
    "sns.barplot(data=df, x=\"bank\", y=\"sentiment_score\")\n",
    "plt.title(\"Average Sentiment Score by Bank\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.xlabel(\"Bank\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774db163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizations\n",
    "sns.countplot(data=df, x=\"sentiment_label\", hue=\"bank\")\n",
    "plt.title(\"Sentiment Label Distribution by Bank\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e41058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "positive_text = \" \".join(positive_reviews[\"review\"])\n",
    "negative_text = \" \".join(negative_reviews[\"review\"])\n",
    "\n",
    "WordCloud(background_color='white', width=800, height=400).generate(positive_text).to_image().show()\n",
    "WordCloud(background_color='black', width=800, height=400).generate(negative_text).to_image().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c892829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert identified_themes to lists\n",
    "df[\"themes_list\"] = df[\"identified_themes\"].apply(lambda x: x.split(\", \"))\n",
    "\n",
    "from itertools import chain\n",
    "theme_counts = pd.Series(list(chain(*df[\"themes_list\"]))).value_counts().head(10)\n",
    "\n",
    "theme_counts.plot(kind=\"bar\", title=\"Top Themes in Reviews\")\n",
    "plt.ylabel(\"Number of Mentions\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
